{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import dlpro\n",
    "from dlpro import constants, data, eval, layers, models, pipelines, reports, utils\n",
    "import tensorflow as tf\n",
    "from dlpro.eval.rt_eval import delta95_metric\n",
    "from dlpro.eval.rt_eval import TimeDeltaMetric\n",
    "from dlpro.data.RetentionTimeDataset import RetentionTimeDataset\n",
    "from dlpro.models.prosit import PrositRetentionTimePredictor\n",
    "from dlpro.reports.RetentionTimeReport import RetentionTimeReport\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import LogLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To save the history as dict\n",
    "# import pickle\n",
    "\n",
    "import functions # -> the functions written for this analysis are being called from functions.py file in dlpro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_FILE_PATH = \"/scratch/yangyang_0.01FDR/evidence.txt\" # raw data location from the server to filer it for further use \n",
    "\n",
    "PROSIT_DATAPATH = \"/scratch/prosit_original/data.csv\"\n",
    "\n",
    "BASE_MODEL_WEIGHTS = \"./prosit_ekin_training_best_checkpoint\"\n",
    "\n",
    "TEST_DATAPATH = \"/scratch/dongxue_tissue_1.0FDR/dongxue_P013129_no_fdr_irt_holdout_data.csv\" # do the denormalization with this data when predict with base model\n",
    "\n",
    "TRAIN_DATAPATH = \"/scratch/dongxue_tissue_0.01FDR/dongxue_P013129_irt_train_data.csv\"\n",
    "\n",
    "DATA_TO_BE_INDEXED = \"./yangyang_0.01FDR/filtered_yangyang_0.01FDR.csv\" # should be a filtered data\n",
    "\n",
    "refinement_training_data = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
    "                              pad_length=30, batch_size=1024, val_ratio=0.25, test=False, sample_run=False)\n",
    "\n",
    "test_data = RetentionTimeDataset(data_source = TEST_DATAPATH,\n",
    "                              pad_length=30, batch_size=64, test=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering raw files\n",
    "    > Filtering according to duplicates with low scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_filter(RAW_FILE_PATH, new_folder_name = \"yangyang_0.01FDR\") # both 0.01 and 1.0 FDR files should be filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data\n",
    "    > The visualization can be used with any files with sequence and irt columns (or rt). It will show the histograms of rt value and sequence length distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributionVisualization(\"./yangyang_0.01FDR/\",\"filtered_yangyang_0.01FDR.csv\",header=\"Yangyang 0.01 FDR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be the location of filtered data inside of the folder created by raw_data_filter() function\n",
    "# and this data should contain only rt values, meaning not indexed \n",
    "FILTERED_DATAPATH = \"./dongxue_1.0_FDR/filtered_dongxue_1.0_FDR.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_DF = indexingDataPreparation(FILTERED_DATAPATH,PROSIT_DATAPATH) \n",
    "# creates indexing data frame to create linear reg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgr = build_regression_model(reference_DF) # creates a regression model with provided df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexandsplit(DATA_TO_BE_INDEXED, rgr, irt_data_name=\"indexed_yangyang_0.01FDR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRefine(rtdata, BASE_MODEL_WEIGHTS,new_weights_file_name=\"yangyang_0.01FDR_refinement\",\n",
    "            learning_rate=0.0000001,SEQ_LENGTH = 30,epoch_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the refinement history, just read the history DF that the modelRefine() function created\n",
    "history = pd.read_csv(\"yangyang_0.01FDR_refinement_historyDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with a model \n",
    "    > This does not have to be the refined model, but the parameters should be defined accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFINED_MODEL_WEIGHTS_PATH = \"./dongxue_indexed_P013129_refinement/weight_118_0.04123\" \n",
    "# the folder created automatically with modelRefine() function (by given name to that function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions,test_targets = modelPredict(REFINED_MODEL_WEIGHTS_PATH,test_data,refinement_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_plot(model_predictions,test_targets,header = \"Dongxue Refined Model Test with \\nDongxue 1.0 FDR Holdout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Predictions Data Frame for SVM analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDataFrame(model_predictions, test_targets, test_rtdata, modelName =\"DongxueRefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this location should adress the prediction data frame created with the predictionDataFrame() function above \n",
    "PREDICTION_DF_LOCATION = \"./SVM_DataFrames/DongxueRefinedModelPredictionDF.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data to be used in the svmFormatter() function should be the indexed and filtered file of the predicted peptides \n",
    "# that file will come from indexandsplit() function, created with the given irt_data_name parameter of the function\n",
    "INDEXED_AND_FILTERED_DATAPATH = \"./\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmFormatter(INDEXED_AND_FILTERED_DATAPATH, PREDICTION_DF_LOCATION, header = \"DongxueRefined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mokapot analysis \n",
    "    > Identification follows the pipeline, but could not install and import mokapot package here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mokapot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psms = mokapot.read_pin(\"phospho_rep1.pin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results, models = mokapot.brew(psms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.to_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
